# config.yaml
seed_everything: 1

trainer:
  max_epochs: 10
  accelerator: "gpu"
  devices: [0]
  precision: "16-mixed"
  accumulate_grad_batches: 16 
  log_every_n_steps: 10
  default_root_dir: "./../checkpoints/"
  
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        save_top_k: 1
        monitor: "train_loss"
        mode: "min"
        save_last: true
        filename: "best-{epoch}-{step}-{train_loss:.4f}"

model:
  learning_rate: 0.0001
  vocab_size: 32005
  hidden_size: 768
  num_hidden_layers: 12
  num_attention_heads: 12

data:
  batch_size: 16               
  tokenizer_dir: "/home/camembert/js"
  train_files:
    - "/home/camembert/dataset_g5/fr_part_1.txt"
    - "/home/camembert/dataset_g5/fr_part_2.txt"
    - "/home/camembert/dataset_g5/fr_part_3.txt"