{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "044c9963-3c03-4e90-8b9c-d02cac3884a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11835ff5-c8e6-4116-bd89-8b93cf65df30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modèle chargé sur GPU !\n"
     ]
    }
   ],
   "source": [
    "# Charger ton modèle DÉJÀ ENTRAÎNÉ\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"./camembert-xnli-final\")\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"./camembert-xnli-final\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(\"cuda\")\n",
    "    print(\"✓ Modèle chargé sur GPU !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c58e2238-5f67-4e94-aeb7-5f0c3a0464b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset prêt !\n"
     ]
    }
   ],
   "source": [
    "# Charger dataset\n",
    "dataset = load_dataset(\"xnli\", \"fr\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"premise\"],\n",
    "        examples[\"hypothesis\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"premise\", \"hypothesis\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset.set_format(\"torch\")\n",
    "print(\"Dataset prêt !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72456f12-6970-4cef-b9b4-4471c7b8f998",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8717/3979203926.py:9: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='79' max='79' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [79/79 00:09]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "RÉSULTATS FINAUX SUR TEST SET\n",
      "==================================================\n",
      "Accuracy obtenue : 81.78%\n",
      "Accuracy article : 82.5%\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Évaluation\n",
    "accuracy_metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=TrainingArguments(output_dir=\"./temp\", per_device_eval_batch_size=64),\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# TEST FINAL\n",
    "results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RÉSULTATS FINAUX SUR TEST SET\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Accuracy obtenue : {results['eval_accuracy']*100:.2f}%\")\n",
    "print(f\"Accuracy article : 82.5%\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
